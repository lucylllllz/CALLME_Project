{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c266ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"s-s\".__contains__(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d183759a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Code Country Code  ID Sex CEFR Level  \\\n",
      "0   L_001           SG   1   F              \n",
      "1  HW_001           SG   2   F              \n",
      "2   J_001           SG   3   M              \n",
      "3   L_002           SG   4   F              \n",
      "\n",
      "                                          PTJ_PIC_xx  \\\n",
      "0   A few weeks ago. This boy was thinking to go ...   \n",
      "1  A few weeks ago. This boy was dreaming about a...   \n",
      "2  A few weeks ago, I wanted to go surfing and sw...   \n",
      "3  A few weeks ago. The boy. Thought of going swi...   \n",
      "\n",
      "                                             1_image  \\\n",
      "0   A few weeks ago. This boy was thinking to go ...   \n",
      "1  A few weeks ago. This boy was dreaming about a...   \n",
      "2  A few weeks ago, I wanted to go surfing and sw...   \n",
      "3  A few weeks ago. The boy. Thought of going swi...   \n",
      "\n",
      "                                             2_image  \\\n",
      "0             , but he realized that he got no money   \n",
      "1  But then he realized that. He was absolutely b...   \n",
      "2              However, I did not have enough money.   \n",
      "3                         But then. He had no money.   \n",
      "\n",
      "                                             3_image  \\\n",
      "0              So he saw a poster. Asking for staff.   \n",
      "1  However. as luck would have it he noticed a po...   \n",
      "2  And fortunately I saw that. There was a hiring...   \n",
      "3  so he decided And he passed by. Job. What do y...   \n",
      "\n",
      "                                             4_image  \\\n",
      "0                                 So he went to work   \n",
      "1  So he went to sign up for it, and he got the j...   \n",
      "2                    So I decided to work their job    \n",
      "3  Which he took up a sales position to sell comp...   \n",
      "\n",
      "                                             5_image  \\\n",
      "0                                  and he got money,   \n",
      "1  A few weeks later. He managed to save up enoug...   \n",
      "2                             to save up some money.   \n",
      "3                           And he earned a salary.    \n",
      "\n",
      "                                             6_image  clip_score_1  \\\n",
      "0                 and then he went for his holiday.      20.983881   \n",
      "1   And went on the trip with his friends in the ...     26.033180   \n",
      "2  So that I could go to the beach and play with ...     20.166582   \n",
      "3  So he used it to go to the beach and swim with...     21.010593   \n",
      "\n",
      "   clip_score_2  clip_score_3  clip_score_4  clip_score_5  clip_score_6  \\\n",
      "0     22.744776     24.823460     18.899969     22.122965     21.742451   \n",
      "1     20.595995     23.208006     23.788906     23.245642     23.419109   \n",
      "2     19.853292     22.541309     19.648172     21.905678     23.136347   \n",
      "3     21.580105     21.537901     24.118931     21.160418     21.512686   \n",
      "\n",
      "   clip_mean  \n",
      "0  21.886250  \n",
      "1  23.381806  \n",
      "2  21.208563  \n",
      "3  21.820106  \n",
      "Saved CLIP scores to selected_clip_scores.xlsx\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch, os, numpy as np, pandas as pd\n",
    "import re\n",
    "# --- setup ---\n",
    "imagedir = \"images/real-1\"\n",
    "teach_df = pd.read_excel(\"teacher_transcript_PTJ.xlsx\")\n",
    "teach_df = teach_df.fillna(\"\")\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").eval()\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "\n",
    "def clip_image_text_score(image_paths, text):\n",
    "    \"\"\"Compute average CLIP similarity between image(s) and all short sentences.\"\"\"\n",
    "    sims = []\n",
    "    # Split long captions by punctuation or newline\n",
    "    segments = re.split(r'[.!?]', text)\n",
    "    segments = [seg.strip() for seg in segments if len(seg.strip()) > 0]\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        for seg in segments:\n",
    "            inputs = clip_processor(text=[seg], images=image, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            with torch.no_grad():\n",
    "                outputs = clip_model(**inputs)\n",
    "                sims.append(outputs.logits_per_image[0, 0].item())\n",
    "\n",
    "    # Take mean or max similarity across all sentence fragments\n",
    "    return float(np.nanmax(sims)) if sims else float(\"nan\")\n",
    "\n",
    "# --- compute per-frame scores for each row ---\n",
    "clip_scores = []\n",
    "\n",
    "for _, row in teach_df.iterrows():\n",
    "    row_scores = []\n",
    "    for i in range(1, 7):\n",
    "        img_path = os.path.join(imagedir, f\"{i}.png\")\n",
    "        caption = row.get(f\"{i}_image\", \"\")\n",
    "        score = clip_image_text_score([img_path], caption)\n",
    "        row_scores.append(score)\n",
    "    clip_scores.append(row_scores)\n",
    "\n",
    "# --- make new DataFrame with same columns + scores ---\n",
    "teach_df1 = teach_df.copy()\n",
    "for i in range(6):\n",
    "    teach_df1[f\"clip_score_{i+1}\"] = [s[i] for s in clip_scores]\n",
    "\n",
    "teach_df1[\"clip_mean\"] = [np.nanmean(s) for s in clip_scores]\n",
    "\n",
    "# --- save or preview ---\n",
    "print(teach_df1.head())\n",
    "teach_df1.to_excel(\"teacher_clip_scores.xlsx\", index=False)\n",
    "print(\"Saved CLIP scores to selected_clip_scores.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6620c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
